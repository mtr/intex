#! /usr/bin/python
# -*- coding: latin-1 -*-
# $Id$
"""

Copyright (C) 2005, 2006 by Martin Thorsen Ranang
"""

__revision__ = "$Rev$"
__author__ = "Martin Thorsen Ranang"

from itertools import chain, count, cycle, ifilter, ifilterfalse, islice, izip, repeat

import logging
import optparse
import os
import re
import sys
import tempfile

INTEX_INDEX = 'raw'
INTEX_EXT = 'intex'

READ_BUF_SIZE = 4096

intex_re = re.compile('\\\@writefile\{%s\}' \
                      '\{\\\indexentry\{(?P<key>.*)\}\{(?P<page>\d+)\}\}' \
                      % (INTEX_INDEX))

    
class Concept(object):
    """
    A class representing a single concept.
    """
    xname = None
    
    def __init__(self, key, in_text='', sort_as='', parent=None):
        self.__equivalencies = list()
        self.__name = self.xname
        self.key = key
        self.in_text = in_text
        self.sort_as = sort_as
        self.parent = parent
        
        self.setup_phenotype()

        typeset_attrs = ('concept',
                         'sub_concept',
                         'sub_entry',
                         'sort_as',
                         'typeset_as',
                         'name',
                         'full_form', )
        
        self.__typeset_info = dict((attr, getattr(self, attr))
                                   for attr in typeset_attrs)
        
        if self.parent:
            parent_attrs = ('typeset_as',
                            'full_form')
            self.__typeset_info.update(('parent_%s' % attr,
                                        getattr(self.parent, attr))
                                       for attr in parent_attrs)
            
    @staticmethod
    def is_sub_entry(field):
        try:
            return field[0] == ':'
        except IndexError:
            return True

    def expand_plural_form(self, form):
        if form and (form[0] == '#'):
            full = (self.parent.in_text \
                    and self.parent.in_text[0] \
                    or self.parent.key)
            if form[1] == 'y':
                if full[-1] == 'y':
                    return full[:-1] + 'ies'
                else:
                    logging.warning("'y' --> 'ies' transformation " \
                                    "specified, but 'y' not last in " \
                                    "full-form ('%s')", full)
            elif form[1] == 's':
                return full + 's'
        else:
            return form
        
    def setup_phenotype(self):
        """
        Defines the attributes used for typesetting this concept (both
        in the running text and in the index).
        """
        if self.parent:
            self.concept = self.parent.concept
            self.sub_concept = self.key
        else:
            self.concept = self.key
            self.sub_concept = ''

  
        self.full_form, self.typeset_as = \
                        islice(chain(ifilterfalse(self.is_sub_entry,
                                                  self.in_text),
                                     repeat('')), 2)

        self.full_form = self.expand_plural_form(self.full_form)

        #print 'self.full_form, self.typeset_as:', [self.full_form, self.typeset_as]
        
        # ':sub_entry' (for the index):
        try:
            self.sub_entry = '!%s' % ([field[1:] for field in self.in_text
                                       if self.is_sub_entry(field)][0], )
        except IndexError:
            if self.typeset_as:
                self.sub_entry = '!%s' % (self.typeset_as)
            else:
                self.sub_entry = ''
                
        if (not self.parent):
            if (not self.typeset_as):
                self.typeset_as = self.concept

        # Sort as:
        if self.sort_as:
            self.sort_as = '%s@' % (self.sort_as)
        elif self.full_form:
            self.sort_as = '%s@' % (self.full_form)
            
        self.sort_as = self.sort_as.replace('\-', '')
        
    def get_typeset_info(self, **args):
        if args:
            args.update(self.__typeset_info)
            return args
        else:
            return self.__typeset_info
        
    def get_name(self):
        return self.__name
    
    name = property(get_name, )
    
    def add_equivalency(self, equivalency):
        """
        Add a concept that is defined to be equivalent/synonymous with
        SELF.
        """
        self.__equivalencies.append(equivalency)
    
    def get_keys(self):
        """
        A generator accessor that yields the key of each concept
        equivalent with the current one.
        """
        yield self.key
        
        for equivalent in self.equivalencies:
            yield equivalent.key
            
    keys = property(get_keys, )
    
    def get_equivalencies(self):
        """
        Return the equivalent concepts of SELF.
        """
        return (equivalency
                for equivalency in self.__equivalencies)

    equivalencies = property(get_equivalencies, )
                
    @staticmethod
    def is_plain():
        return False

    @staticmethod
    def is_acronym():
        return False

    @staticmethod
    def is_person():
        return False

    @staticmethod
    def is_equivalency():
        return False

    def generate_index_entry(self, index_name, page):
        #args = self._setup_index_args(index_name, page, self.key, self.sort_as)
        return '\indexentry{%(sort_as)s%(concept)s}{%(page)s}' \
               % (self.get_typeset_info(index_name=index_name, page=page))

    def generate_index_entries(self, index_name, page):
        """
        Generate all the index entries (including sub-entries) for
        this concept.
        """
        yield self.generate_index_entry(index_name, page)
        
        for equivalency in self.equivalencies:
            yield equivalency.generate_index_entry(index_name, page)

    def generate_aux_modification(self):
        return '\\new%(name)s{%(concept)s}{%(typeset_as)s}{%(full_form)s}' \
               % (self.get_typeset_info())
    
    def generate_aux_modifications(self):
        """
        Generate all the aux-file modifications (including
        sub-entries) for this concept.
        """
        yield self.generate_aux_modification()
        
        for equiv in self.equivalencies:
            yield equiv.generate_aux_modification()


class PlainConcept(Concept):
    xname = 'concept'
    
    @staticmethod
    def is_plain():
        return True
    
    #def generate_aux_modification(self):
    #    return '\\new%s{%s}{%s}{}' % (self.name, self.key, self.key)
            
class AcronymConcept(Concept):
    xname = 'acronym'
    
    @staticmethod
    def is_acronym():
        return True

    def generate_index_entry(self, index_name, page):
        return '\indexentry{%(sort_as)s%(full_form)s}{%(page)s}\n' \
               '\indexentry{%(typeset_as)s|see{%(full_form)s}}{%(page)s}' \
               % (self.get_typeset_info(index_name=index_name, page=page))
            
class PersonConcept(Concept):
    xname = 'person'
    
    @staticmethod
    def is_person():
        return True
    
class Equivalency(Concept):
    xname = 'equiv'
    
    @staticmethod
    def is_equivalency():
        return True

    def setup_phenotype(self):
        Concept.setup_phenotype(self)
        
        if (not self.full_form) and (self.sub_concept.startswith(self.concept)):
            added = self.sub_concept.replace(self.concept, '', 1)
            print 'added:', added
            if added:
                self.full_form = self.parent.full_form + added
                
        # If not SELF.IN_TEXT, then we've got no explicit
        # typesetting info.
        if (not self.typeset_as):
            if (self.parent.typeset_as != self.parent.concept) \
                   and self.sub_concept.startswith(self.concept):
                added = self.sub_concept.replace(self.concept, '', 1)
                self.typeset_as = self.parent.typeset_as + added
            else:
                self.typeset_as = self.sub_concept
                
    def generate_aux_modification(self):
        return '\\new%(name)s{%(concept)s}{%(typeset_as)s}' \
               '{%(sub_concept)s}{%(full_form)s}' \
               % (self.get_typeset_info())
    
    def generate_index_entry(self, index_name, page):
        return '\\indexentry{%(sort_as)s%(concept)s%(sub_entry)s}{%(page)s}' \
               % (self.get_typeset_info(index_name=index_name, page=page))
    
    def generate_index_entries(self, **args):
        raise (NotImplementedError,
               'The %s class does not implement this method.' %
               self.__class__.__name__)
    
    def generate_aux_modifications(self, **args):
        raise (NotImplementedError,
               'The %s class does not implement this method.' %
               self.__class__.__name__)
    
class PlainEquivalency(Equivalency):
    xname = 'conceptequiv'

class AcronymEquivalency(Equivalency):
    xname = 'acronymequiv'
    
            
    def generate_index_entry(self, index_name, page):
        return '\\indexentry{%(sort_as)s%(parent_full_form)s%(sub_entry)s}{%(page)s}' \
               % (self.get_typeset_info(index_name=index_name, page=page))
    
class PersonEquivalency(Equivalency):
    xname = 'personequiv'

    
class InTeX(object):
    delimiter = '\t'
    
    def __init__(self, filenames):
        identifiers = dict()
        
        for filename in filenames:
            identifiers[filename] = self.parse(filename)
            
        self.index = dict()
        seen_kinds = set()
        
        for filename, concepts in identifiers.items():
            for concept in concepts:
                seen_kinds.add(concept.__class__.__name__)
                
                for key in concept.get_keys():
                    self.index[key] = concept
        
        self.identifiers = identifiers
        self.used_kinds = tuple(seen_kinds)

    def __str__(self):
        return str(self.index)
    
    def __contains__(self, key):
        return self.index.__contains__(key)

    def __getitem__(self, key):
        return self.index.__getitem__(key)

    @staticmethod
    def handle_fields(fields, serial_number):
        #info = {'serial': serial_number}
        info = dict()
        
        info['key'], fields = fields[0], fields[1:]
        
        if fields and fields[-1][0] == '@':
            info['sort_as'] = fields.pop()[1:]
            
        info['in_text'] = tuple(fields)
        
        return info

    __kind_class_map = {
        'person': PersonConcept,
        'acronym': AcronymConcept,
        'concept': PlainConcept,
        'person_equiv': PersonEquivalency,
        'acronym_equiv': AcronymEquivalency,
        'concept_equiv': PlainEquivalency,
        }
    
    def parse_line(self, line, concepts, kind, serial_number=0):
        if line[0].isspace():
            # An equivalent form of the current index entry.
            kind = '%s_equiv' % (kind, )
            fields = self.handle_fields(line.lstrip().split(self.delimiter),
                                        serial_number)
            fields['parent'] = concepts[-1]
            concepts[-1].add_equivalency(self.__kind_class_map[kind](**fields))
            
        else:
            # A new index entry.  Can be 'person', 'acronym', or 'plain'.
            fields = self.handle_fields(line.split(self.delimiter),
                                        serial_number)
            concepts.append(self.__kind_class_map[kind](**fields))
            
    def parse(self, filename):
        concepts = []
        mode_switch_re = re.compile('^%[ ]*\*' \
                                    '(?P<kind>persons|acronyms|concepts)\*',
                                    re.IGNORECASE)
        kind = 'concept'                # Default "mode".

        serial_number = 1
        in_file = open(filename, 'r')
        for line in in_file:
            line = line.rstrip("\n")
            if not line:
                continue
            if line[0] == '%':
                match = mode_switch_re.match(line)
                if match:
                    # New current KIND (or mode).
                    kind = match.group('kind')[:-1].lower()
                continue
            
            self.parse_line(line, concepts, kind, serial_number)
            serial_number += 1
            
        in_file.close()
        
        return concepts

def get_entries(filename):
    for line in open(filename, 'r'):
        match = intex_re.match(line.rstrip())
        if not match:
            yield (False, line)
            continue
        yield (True, match.groups())
        
def handle_auxiliary(aux_filename, index, index_file, tmp_aux_file):
    not_found = []
    already_handled = set()
    already_printed = set()
    
    for is_concept, data in get_entries(aux_filename):
        if not is_concept:
            tmp_aux_file.write(data)
            continue
        
        key, page = data
        
        if key not in index:
            not_found.append((key, page))
            continue
        
        concept = index[key]

        for line in concept.generate_index_entries(INTEX_INDEX, page):
            if line not in already_printed:
                print >> index_file, line
                already_printed.add(line)
                
        if key not in already_handled:
            for line in concept.generate_aux_modifications():
                if line not in already_printed:
                    print >> tmp_aux_file, line
                    already_printed.add(line)
                    
            already_handled.add(key)
            
    return not_found

def copy(src_name, dst_name):
    src, dst = open(src_name, 'r'), open(dst_name, 'w')
    while True:
        data = src.read(READ_BUF_SIZE)
        if data == '':
            break
        dst.write(data)
        
    dst.close()
    src.close()

auto_edit_warning = '''
%%%% This file was automatically generated by InTeX version %s,
%%%% copyright (C) 2005, 2006 by Martin Thorsen Ranang.  Any manual changes
%%%% made to this file will be lost next time InTeX is run with the
%%%% same arguments.
''' % (__revision__)

def generate_acrodefs(index):
    res = []
    for concepts in index.identifiers.values():
        for concept in ifilter(lambda concept: concept.is_acronym(), concepts):
            if len(concept.in_text) > 1:
                typeset_as = concept.in_text[1]
            else:
                typeset_as = concept.key

            res.append('\\newacronym{%s}{%s}{%s}' \
                       % (concept.key, typeset_as,
                          concept.in_text[0]))
    return res

def generate_persondefs(index):
    res = []
    for concepts in index.identifiers.values():
        for concept in ifilter(lambda concept: concept.is_person(), concepts):
            if len(concept.in_text) > 1:
                res.append('\\newperson{%s}{%s}{%s}' \
                           % (concept.key, concept.in_text[1],
                              concept.in_text[0]))
            else:
                res.append('\\newperson{%s}{%s}' \
                           % (concept.key, concept.in_text[0]))
    return res

def resolve_auxiliary_and_args(args):
    aux_re = re.compile('^.*\.aux$', re.IGNORECASE)
    auxiliary = [arg for arg in args
                 if aux_re.match(arg) and os.path.exists(arg)]
    args = [arg for arg in args if arg not in auxiliary]

    attempts = count(-2)
    
    while attempts.next():
        if len(auxiliary) > 1:
            logging.error('Please explicitly specify the ' \
                          'LaTeX auxiliary (.aux) file to use.')
            sys.exit(1)
            
        elif not auxiliary:
            auxiliary = ['%s.aux' % (arg) for arg in args
                         if os.path.exists('%s.aux' % (arg))]
            args = [arg for arg in args if '%s.aux' % (arg) not in auxiliary]
            
        else:
            auxiliary = auxiliary[0]
            break
        
    return auxiliary, args


def parse_command_line(command_line_options):
    """
    Parse the command line according to the possible COMMAND_LINE_OPTIONS.
    """
    parser = optparse.OptionParser(usage = '%prog [options]...',
                                   version = '%%prog %s' % (__revision__))
    for option, description in command_line_options:
        parser.add_option(*option, **description)
        
    # Parse the command line.
    options, args = parser.parse_args()
    return options, args


def main():
    """
    Module mainline (for standalone execution).
    """
    command_line_options = [
        (['-o', '--index-output'],
         {'dest': 'index_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output the new indexing information to FILE'}),
        (['-a', '--acrodef-output'],
         {'dest': 'acrodef_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output acronym definitions to FILE'}),
        (['-p', '--persondef-output'],
         {'dest': 'persondef_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output (person) name definitions to FILE'}),
        (['-V', '--verbose'],
         {'dest': 'verbose',
          'default': False,
          'action': 'store_true',
          'help': 'whether or not to output verbose information'}),
        ]
    
    options, args = parse_command_line(command_line_options)
    
    auxiliary, args = resolve_auxiliary_and_args(args)

    logging.root.name = sys.argv[0]
    
    if not auxiliary:
        logging.warning('No LaTeX auxiliary file specified.')
        sys.exit(1)
        
    if len(args) == 0:
        suffix_re = re.compile('^.*\.%s$' % (INTEX_EXT))
        
        filenames = [filename
                     for filename in os.listdir(os.getcwd())
                     if suffix_re.match(filename)]
    else:
        filenames = args
    
    for filename in filenames:
        if not os.path.exists(filename):
            logging.error("File '%s' not found", filename)
            sys.exit(1)
            
    if options.verbose:
        logging.info('LaTeX Auxiliary file: %s', auxiliary)
        logging.info('Concept-files:\n%s', '\n'.join(filenames))
        
    index = InTeX(filenames)

    for option, meta_information, kind in ((options.index_output,
                                            'index information',
                                            'PlainConcept'),
                                           (options.acrodef_output,
                                            'acronym definitions',
                                            'AcronymConcept'),
                                           (options.persondef_output,
                                            '(proper)name definitions',
                                            'PersonConcept')):
        if (kind and (kind in index.used_kinds) and (not option)):
            logging.error('Missing name for file wherein ' \
                          '%s will be stored.', meta_information)
            return 1
        elif (kind and option and (kind not in index.used_kinds)):
            logging.warning("name for file wherein " \
                            "%s will be stored was  supplied ('%s'), " \
                            "but no such input occur.",
                            meta_information, option)
            
    persondef_file = open(options.persondef_output, 'w')
    print >> persondef_file, auto_edit_warning
    print >> persondef_file, '\n'.join(generate_persondefs(index))
    persondef_file.close()
    
    acrodef_file = open(options.acrodef_output, 'w')
    print >> acrodef_file, auto_edit_warning
    print >> acrodef_file, '\n'.join(generate_acrodefs(index))
    acrodef_file.close()
    
    index_file = open(options.index_output, 'w')
    
    # We first create a temporary file.  If any "shit hits the fan"
    # before we're done, the original LaTeX .aux file will be
    # untouched and the temporary version can be inspected.
    tmp_aux_fd, tmp_aux_filename = tempfile.mkstemp('.%s' % (INTEX_EXT))
    tmp_aux_file = os.fdopen(tmp_aux_fd, 'w')
    
    not_found = handle_auxiliary(auxiliary, index,
                                 index_file, tmp_aux_file)

    index_file.close()
    tmp_aux_file.close()
    
    # Everything seems to have worked OK so far.  Now, let's backup
    # the original .aux file and rename the temporarily created one to
    # take the place of the original.
    os.rename(auxiliary, '%s~' % (auxiliary))
    copy(tmp_aux_filename, auxiliary)
    os.unlink(tmp_aux_filename)
    
    if not_found:
        logging.warning('The following phrases ' \
                        'could not be handled:\n%s',
                        ('\n'.join('%s\t%s' % item for item in not_found)))
        
    return

if __name__ == "__main__":
    main()
