#! /usr/bin/python
# -*- coding: utf-8 -*-
# $Id$
"""
Copyright (C) 2007 by Martin Thorsen Ranang
"""
__version__ = "$Rev$"
__author__ = "Martin Thorsen Ranang <mtr@ranang.org>"


import logging
import optparse
import os
import re

TOKEN_COMMENT           = '%'
TOKEN_SHORT_PLURAL_FORM = '#'
TOKEN_ENTRY_META_INFO   = ':'

FIELD_SEPARATORS = '\t,'

def normalize(string, token=None):
    """Returns a new string where multiple consecutive occurences of
    TOKEN have been replaced by a single occurence.  If TOKEN is None,
    it is interpreted as white-space.
    """
    return (token or ' ').join(string.split(token))

class IndexEntry(object):
    # Define a number of class constants, each string will be defined
    # as an all-uppercase "constant".  That is 'this_value' is
    # assigned to __class__.THIS_VALUE.
    for constant in (
        # Different meta fields:
        'meta_plural_form',
        'meta_given_inflection',
        'meta_text_vs_index_hint',
        # Some inflection values:
        'inflection_plural',
        'inflection_singular',
        # Meaning of placeholders:
        'placeholder_in_text_and_index',
        'placeholder_in_text_only',
        ):
        exec("%s='%s'" % (constant.upper(),
                          ''.join(constant.split('_', 1)[1:])))

    __shorthand_inflection = {
        '+': INFLECTION_PLURAL,
        '-': INFLECTION_SINGULAR,
        }
    
    __unescape_re = re.compile(r'(?P<pre>.*?)[\\](?P<post>[%s])' \
                               % FIELD_SEPARATORS)

    # Regular expression for splitting inside meta-fields, but taking
    # care of not splitting on escaped "split-tokens".
    __meta_split_re = re.compile(r'''
    (?<![\\])              # If the previous token was not a "\", then
    %s                     # match a TOKEN_ENTRY_META_INFO.
    ''' % (TOKEN_ENTRY_META_INFO), re.VERBOSE)
    
    def __init__(self, index, parent):
        index.append(self)
        self.__identity = (len(index) - 1)
        self.__index = index
        self.__parent = parent
        self.__children = set()

        if self.parent:
            # Include ourselves among our parent's children.
            self.parent.add_child(self.__identity)

    def parse_meta(self, meta):
        parts = self.__meta_split_re.split(meta)
        
        info = dict()
        
        assert(parts[0] == '')

        for part in parts[1:]:
            if not part:
                logging.error('Unsuspected data in meta directive.')
                
            if not part.startswith('#'):
                info[self.META_TEXT_VS_INDEX_HINT] = part
                continue
            
            if len(part) == 2:
                assert(part[-1] in self.__shorthand_inflection)
                info[self.META_GIVEN_INFLECTION] = \
                            self.__shorthand_inflection[part[1:]]
                
            else:
                info[self.META_PLURAL_FORM] = part[1:]
            
        return info

    def unescape(self, string):
        return self.__unescape_re.sub('\g<pre>\g<post>', string)
    
    # Accessors for the 'identity' property (__-prefixed to force
    # access through the property):
    def __get_identity(self):
        return self.__identity
        
    def __set_identity(self, identity):
        self.__identity = identity
        
    identity = property(__get_identity, __set_identity, None,
                        'The identity of this entry.')

    # Accessors for the 'parent' property (__-prefixed to force
    # access through the property):
    def __get_parent(self):
        if self.__parent == None:
            return None
        return self.__index[self.__parent]
        
    def __set_parent(self, parent):
        self.__parent = parent
        
    parent = property(__get_parent, __set_parent, None,
                      'The parent of this entry.')

    def add_child(self, child_identity):
        self.__children.add(child_identity)
        
    # Accessors for the 'children' property (__-prefixed to force
    # access through the property):
    def __get_children(self):
        return [self.__index[child_id]
                for child_id in sorted(self.__children)]
        
    children = property(__get_children, None, None,
                        'The children of this entry.')

    # Accessors for the 'index' property (__-prefixed to force
    # access through the property):
    def __get_index(self):
        return self.__index

    index = property(__get_index, None, None,
                     'The index that this entry belongs to.')
    
    def to_latex(self):
        raise NotImplementedError

class AcronymEntry(IndexEntry):

    def __init__(self, index, parent, acronym=None,
                 full_form=None, typeset_as=None, plural=None,
                 index_as=None, sort_as=None, meta=None, **rest):
        # Register this entry in the INDEX, set our PARENT and if we
        # do have a parent, add ourselves to that PARENT's set of
        # children.
        IndexEntry.__init__(self, index, parent)
        
        self.__acronym = acronym
        self.__full_form = full_form
        self.__typeset_as = typeset_as

class ConceptEntry(IndexEntry):
    # Note that the order is significant (also when the pairs are
    # reversed below).
    __plural_singular = [
        ('ies', 'y'),
        ('ses', 's'),
        ('s', ''),
        ]

    __singular_plural = [(singular, plural)
                         for plural, singular in __plural_singular]

    __inflection_pair = {
        IndexEntry.INFLECTION_PLURAL:   __plural_singular,
        IndexEntry.INFLECTION_SINGULAR: __singular_plural,
        }

    __placeholder_meaning = {
        '-':   IndexEntry.PLACEHOLDER_IN_TEXT_AND_INDEX,
        '(-)': IndexEntry.PLACEHOLDER_IN_TEXT_ONLY,
        }

    __hint_re = re.compile('(?P<placeholder>%s)' \
                           % '|'.join(map(re.escape, __placeholder_meaning)))
        
    def __init__(self, index, parent, concept=None,
                 plural=None, index_as=None, sort_as=None, meta=None,
                 **rest):
        IndexEntry.__init__(self, index, parent)

        if concept:
            self.__concept = self.unescape(concept.strip())
        else:
            self.__concept = ''

        if meta:
            self.__meta = self.parse_meta(meta.strip())
        else:
            self.__meta = dict()
            
        self.__in_text = []
        self.__typeset_in_text = []
        self.__in_index = []
        self.__typeset_in_index = []
        
        self.__setup()
        
        print self
        
    def __str__(self):
        return '\n'.join(description + ': {' \
                         + ', '.join(map(repr, variants)) + '}'
                         for description, variants \
                         in [('in_text', self.__in_text),
                             ('in_index', self.__in_index),])

    def change_inflection(self, word, inflection_pairs):
        for suffix, replacement in inflection_pairs:
            if word.endswith(suffix):
                offset = (- len(suffix)) or None
                return word[:offset] + replacement
            
        return word

    def __setup(self):
        if self.__concept:
            self.__in_text.append(self.__concept)
            
            if self.META_GIVEN_INFLECTION in self.__meta:
                current_inflection = self.__meta[self.META_GIVEN_INFLECTION]
            else:
                current_inflection = self.index.default_inflection

            inflection_pairs = self.__inflection_pair[current_inflection]
            
            self.__in_text.append(\
                    self.change_inflection(self.__in_text[0],
                                           inflection_pairs))
            
        elif self.__meta[self.META_TEXT_VS_INDEX_HINT]:
            template = self.__meta[self.META_TEXT_VS_INDEX_HINT]
            for match in self.__hint_re.finditer(template):
                placeholder = match.group('placeholder')
                i, j = match.span('placeholder')
                for variant in  self.parent.__in_text:
                    # Construct the new phrase.
                    phrase = template[:i] + variant + template[j:]
                    
                    # Add the new phrase to the in-text variants.
                    self.__in_text.append(phrase)
                    
                    if self.__placeholder_meaning[placeholder] \
                           == self.PLACEHOLDER_IN_TEXT_AND_INDEX:
                        self.__in_index.append(phrase)
                    else:
                        normalized = normalize(template[:i] + template[j:])
                        self.__in_index.append(normalized)
                        
                print template[i:j]
                
class PersonEntry(IndexEntry):
    def __init__(self, index, parent, initials=None,
                 last_name=None, first_name=None, index_as=None,
                 sort_as=None, meta=None, **rest):
        IndexEntry.__init__(self, index, parent)
        
        self.__initials = initials
        self.__last_name = last_name
        self.__first_name = first_name
        
class Index(list):
    __concept_types = ['ACRONYMS', 'PEOPLE', 'CONCEPTS']
    __index_attrbiutes = {
        'name': None,
        }

    __re_macros = {
        'FIELD': '''
        [^%(COMMENT_TOKEN)s:\s]         # Non-comment and non-meta.
        (                               # Either
                                        #  escaped field separators
         \\\\[%(FIELD_SEPARATORS)s%(META_TOKEN)s] 
        |                               # or
                                        #  non-field-separators
         [^%(FIELD_SEPARATORS)s%(META_TOKEN)s] 
        )+                              # repeated.
        ''',
        'FIELD_SEPARATORS': FIELD_SEPARATORS,
        'COMMENT_TOKEN': TOKEN_COMMENT,
        'META_TOKEN': TOKEN_ENTRY_META_INFO,
        }
    __re_macros['FIELD'] = __re_macros['FIELD'] % __re_macros
    
    # Regular expressions, one pattern matcher for each context:
    __concept_re = re.compile('''
    ^                                   # Starts with
    (?P<indent>\s+)?                    # (possible) indentation,
    (?P<concept>%(FIELD)s)?             # an entry,
    [%(FIELD_SEPARATORS)s]*             # a separator,
    (?P<typeset_as>%(FIELD)s)?          # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<meta>%(META_TOKEN)s.+)?         # meta information
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    __acronym_re = re.compile('''
    ^                                   # Starts with
    (?P<indent>\s+)?                    # (possible) indentation,
    (?P<acronym>%(FIELD)s)?               # an entry,
    [%(FIELD_SEPARATORS)s]*             # a separator,
    (?P<full_form>%(FIELD)s)?           # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<typeset_as>%(FIELD)s)?          # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<meta>%(META_TOKEN)s.+)?         # meta information
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    __person_re = re.compile('''
    ^                                   # Starts with
    (?P<indent>\s+)?                    # (possible) indentation,
    (?P<initials>%(FIELD)s)?               # an entry,
    [%(FIELD_SEPARATORS)s]*             # a separator,
    (?P<last_name>%(FIELD)s)?           # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<first_name>%(FIELD)s)?          # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<meta>%(META_TOKEN)s.+)?         # meta information
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    # A map between context names and the match patterns:
    __context_matcher = {
        'ACRONYMS': __acronym_re,
        'CONCEPTS': __concept_re,
        'PEOPLE': __person_re,
        }

    __context_class = {
        'ACRONYMS': AcronymEntry,
        'CONCEPTS': ConceptEntry,
        'PEOPLE': PersonEntry,
        }
        
    # Add a macro definition to the values available when constructing
    # the regular expressions below.
    __re_macros['CONCEPT_TYPES'] = '|'.join(__context_matcher.keys())

    # A pattern to match meta directives:
    __meta_directive_re = re.compile('''
    ^                                   # Starts with
    %(COMMENT_TOKEN)s                   # the comment token,
    \s*                                 # possibly some whitespace,
    (                                   # then either
     (?P<attribute>\w+)\s*              #  an attribute
     =                                  #  sat to
     \s*(?P<value>\w+)                  #  some value,
     |                                  # or
     (?P<context>\*(%(CONCEPT_TYPES)s)\*) #  a context switch
    )                                   # followed by
    \s*                                 # possibly trailing whitespace
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    # A pattern to match comment-only lines.
    __pure_comment_re = re.compile('''
    ^                                   # Starts with
    \s*                                 # possibly some whitespace
    %(COMMENT_TOKEN)s                   # and the comment token,
    .*                                  # followed by anything.
    ''' % __re_macros, re.VERBOSE)

    # A list used to instantiate the context dependent parser.
    __matchers = [
        __meta_directive_re,
        __pure_comment_re,
        None,               # The current context will be placed here.
        ]
    
    def __init__(self, filename=None, index_name='default'):
        """The constructor.
        """
        list.__init__(self)
        
        self.__name = index_name
        self.__current_matchers = list(Index.__matchers)

        self.__indentation_level = {
            '': 0,
            }

        self.__elements = []  # A stack of elements used when parsing.
        #self.__entries = []  # A list of all the entries in the index.
        
    # Accessors for the 'name' property (__-prefixed to force access
    # through the property):
    def __get_name(self):
        return self.__name
        
    def __set_name(self, name):
        self.__name = name
        
    name = property(__get_name, __set_name, None, 'The name of the index.')

    def handle_meta_directive(self, attribute=None, value=None, context=None):
        if attribute:
            # Set an attribute describing this index (e.g., its name).
            setattr(self, attribute, value)
        elif context:
            self.__context = context[1:-1] # Remove pre and post '*'s.
            logging.info('Switching context to: "%s"', self.__context, )
            self.__matchers[-1] = self.__context_matcher[self.__context]
            self.__entry_class = self.__context_class[self.__context]
            
    def handle_comment(self):
        """Do nothing.  (Yes, seriously.)
        """
        pass
    
    def __get_indentation_level(self, indent):
        if indent == None:
            indent = ''
            
        # Make sure that indentation by tabs are expanded.
        indent = indent.expandtabs()
        
        if indent not in self.__indentation_level:
            if len(indent) < max(len(key) for key in self.__indentation_level):
                # The indentation levels should be monotonically
                # increasing.  The first time an indentation level is
                # used, it is also defined and available for the rest
                # of the session.
                raise IndentationError, \
                      'On line %d in file "%s:\n%s' \
                      % ((self.__line_num + 1), self.__current_file,
                         self.__current_line)
            else:
                self.__indentation_level[indent] = len(self.__indentation_level)
                
        return self.__indentation_level[indent]

    def __prepare_element_stack(self, indent):
        level = self.__get_indentation_level(indent)

        while level < len(self.__elements):
            self.__elements.pop()

    def __get_current_parent(self):
        return self.__elements and self.__elements[-1].identity or None
        
    def handle_entry(self, indent=None, **rest):
        self.__prepare_element_stack(indent)
        self.__elements.append(self.__entry_class(self,
                                                  self.__get_current_parent(),
                                                  **rest))
        
    __match_handler = {
        __meta_directive_re: handle_meta_directive,
        __pure_comment_re: handle_comment,
        __concept_re: handle_entry,
        __acronym_re: handle_entry,
        __person_re: handle_entry,
        #__concept_re: handle_concept,
        #__acronym_re: handle_acronym,
        #__person_re: handle_person,
        }
    
    @classmethod
    def from_file(cls, filename):
        self = cls()

        self.__current_file = filename
        
        stream = open(filename, 'r')
        
        for self.__line_num, line in enumerate(stream):
            if line.isspace():
                continue

            # Keep a copy of the original line (for error messages,
            # etc.)
            self.__current_line = line
            
            # Remove trailing white-space.
            line = line.rstrip()        
            
            # Parse the line trying different matchers.  Quit trying
            # after the first applicable matcher is used.
            for matcher in self.__matchers:
                for match in matcher.finditer(line):
                    # Call the appropriate handler, given the current
                    # context.
                    self.__match_handler[matcher](self, **match.groupdict())
                    break               # To avoid the else clause.
                else:
                    continue            # The matcher didn't apply.
                break                   # Skip the remaining matchers.
            
        stream.close()            # Explicitly close the input stream.

        self.__current_file = None
        
        return self
        
def parse_command_line(command_line_options):
    """Parse the command line according to the possible
    COMMAND_LINE_OPTIONS.
    """
    parser = optparse.OptionParser(usage='%prog [options]...',
                                   version='%%prog %s' % (__version__))
    for option, description in command_line_options:
        parser.add_option(*option, **description)
        
    # Parse the command line.
    return parser.parse_args()
        
def main():
    """Module mainline (for standalone execution).
    """
    command_line_options = [
        (['-O', '--feedback'],
         {'dest': 'feedback',
          'default': None,
          'metavar': 'FILE',
          'help': 'output the new internal InTeX information to FILE ' \
          '(default: %default)'}),
        (['-o', '--index-output'],
         {'dest': 'index_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output the new indexing information to FILE ' \
          '(default: %default)'}),
        (['-a', '--acrodef-output'],
         {'dest': 'acrodef_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output acronym definitions to FILE ' \
          '(default: %default)'}),
        (['-p', '--persondef-output'],
         {'dest': 'persondef_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output (person) name definitions to FILE ' \
          '(default: %default)'}),
        (['-V', '--verbose'],
         {'dest': 'verbose',
          'default': False,
          'action': 'store_true',
          'help': 'whether or not to output verbose information'}),
        ]

    options, args = parse_command_line(command_line_options)

    logging.root.name = os.path.basename(__file__)

    # Configure the logging module.
    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s',
                        level=(options.verbose and logging.INFO or None))
    
    indices = [Index.from_file(filename) for filename in args]
        
if __name__ == "__main__":
    main()
