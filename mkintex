#! /usr/bin/python
# -*- coding: utf-8 -*-
# $Id$
"""
Copyright (C) 2007 by Martin Thorsen Ranang
"""
__version__ = "$Rev$"
__author__ = "Martin Thorsen Ranang <mtr@linpro.no>"


import logging
import optparse
import os
import re

TOKEN_COMMENT           = '%'
TOKEN_SHORT_PLURAL_FORM = '#'
TOKEN_ENTRY_META_INFO   = ':'

class IndexEntry(object):
    def to_latex(self):
        raise NotImplementedError

class AcronymEntry(IndexEntry):
    def __init__(self, acronym, full_form, typeset_as=None,
                 plural=None, index_as=None, sort_as=None):
        self.__initials = initials
        self.__last_name = last_name,
        self.__first_name = first_name

class PersonEntry(IndexEntry):
    def __init__(self, initials, last_name, first_name=None,
                 index_as=None, sort_as=None):
        self.__initials = initials
        self.__last_name = last_name,
        self.__first_name = first_name

class PlainEntry(IndexEntry):
    def __init__(self, concept,
                 plural=None, index_as=None, sort_as=None):
        self.__plural = plural
        self.__sub_entry = sub_entry
        
        self.__initials = initials
        self.__last_name = last_name,
        self.__first_name = first_name
        
class Index(list):
    __concept_types = ['ACRONYMS', 'PEOPLE', 'CONCEPTS']
    __index_attrbiutes = {
        'name': None,
        }

    __re_macros = {
        'FIELD': '''
        [^%(COMMENT_TOKEN)s:\s]         # Non-comment and non-meta.
        (                               # Either
                                        #  escaped field separators
         \\\\[%(FIELD_SEPARATORS)s%(META_TOKEN)s] 
        |                               # or
                                        #  non-field-separators
         [^%(FIELD_SEPARATORS)s%(META_TOKEN)s] 
        )+                              # repeated.
        ''',
        'FIELD_SEPARATORS': '\t,',
        'COMMENT_TOKEN': TOKEN_COMMENT,
        'META_TOKEN': TOKEN_ENTRY_META_INFO,
        }
    __re_macros['FIELD'] = __re_macros['FIELD'] % __re_macros
    
    # Regular expressions, one pattern matcher for each context:
    __concept_re = re.compile('''
    ^                                   # Starts with
    (?P<indent>\s+)?                    # (possible) indentation,
    (?P<entry>%(FIELD)s)?               # an entry,
    [%(FIELD_SEPARATORS)s]*             # a separator,
    (?P<typeset_as>%(FIELD)s)?          # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<meta>%(META_TOKEN)s.+)?         # meta information
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    __acronym_re = re.compile('''
    ^                                   # Starts with
    (?P<indent>\s+)?                    # (possible) indentation,
    (?P<acronym>%(FIELD)s)?               # an entry,
    [%(FIELD_SEPARATORS)s]*             # a separator,
    (?P<full_form>%(FIELD)s)?           # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<typeset_as>%(FIELD)s)?          # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<meta>%(META_TOKEN)s.+)?         # meta information
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    __person_re = re.compile('''
    ^                                   # Starts with
    (?P<indent>\s+)?                    # (possible) indentation,
    (?P<initials>%(FIELD)s)?               # an entry,
    [%(FIELD_SEPARATORS)s]*             # a separator,
    (?P<last_name>%(FIELD)s)?           # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<first_name>%(FIELD)s)?          # the full form,
    [%(FIELD_SEPARATORS)s]*             # another separator,
    (?P<meta>%(META_TOKEN)s.+)?         # meta information
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    # A map between context names and the match patterns:
    __context_matcher = {
        'ACRONYMS': __acronym_re,
        'CONCEPTS': __concept_re,
        'PEOPLE': __person_re,
        }

    # Add a macro definition to the values available when constructing
    # the regular expressions below.
    __re_macros['CONCEPT_TYPES'] = '|'.join(__context_matcher.keys())

    # A pattern to match meta directives:
    __meta_directive_re = re.compile('''
    ^                                   # Starts with
    %(COMMENT_TOKEN)s                   # the comment token,
    \s*                                 # possibly some whitespace,
    (                                   # then either
     (?P<attribute>\w+)\s*              #  an attribute
     =                                  #  sat to
     \s*(?P<value>\w+)                  #  some value,
     |                                  # or
     (?P<context>\*(%(CONCEPT_TYPES)s)\*) #  a context switch
    )                                   # followed by
    \s*                                 # possibly trailing whitespace
    $                                   # at the end.
    ''' % __re_macros, re.VERBOSE)

    # A pattern to match comment-only lines.
    __pure_comment_re = re.compile('''
    ^                                   # Starts with
    \s*                                 # possibly some whitespace
    %(COMMENT_TOKEN)s                   # and the comment token,
    .*                                  # followed by anything.
    ''' % __re_macros, re.VERBOSE)

    # A list used to instantiate the context dependent parser.
    __matchers = [
        __meta_directive_re,
        __pure_comment_re,
        None,               # The current context will be placed here.
        ]
    
    def __init__(self, filename=None, index_name='default'):
        list.__init__(self)
        
        self.__name = index_name
        self.__current_matchers = list(Index.__matchers)
        
    # Accessors for the 'name' property:
    def get_name(self):
        return self.__name
        
    def set_name(self, name):
        self.__name = name
        
    name = property(get_name, set_name, None, 'The name of the index.')

    def handle_meta_directive(self, attribute=None, value=None, context=None):
        if attribute:
            setattr(self, attribute, value)
        elif context:
            self.__context = context[1:-1]
            print 'Switching context to: "%s"' % (self.__context, )
            self.__matchers[-1] = self.__context_matcher[self.__context]
            

    def handle_comment(self):
        """Seriously, do nothing.
        """
        pass
        
    def handle_acronym(self, acronym=None, full_form=None, typeset_as=None,
                       indent=None, meta=None):
        print indent and indent or '\r',
        print acronym, full_form, typeset_as, meta

    def handle_concept(self, entry=None, typeset_as=None,
                       indent=None, meta=None):
        print indent and indent or '\r',
        print entry, typeset_as, meta


    def handle_person(self, initials=None, last_name=None, first_name=None,
                      indent=None, meta=None):
        print initials, last_name, first_name

    __match_handler = {
        __meta_directive_re: handle_meta_directive,
        __pure_comment_re: handle_comment,
        __concept_re: handle_concept,
        __acronym_re: handle_acronym,
        __person_re: handle_person,
        }
    
    @classmethod
    def from_file(cls, filename):
        self = cls()
        
        stream = open(filename, 'r')
        
        for line in stream:
            if line.isspace():
                continue

            # Remove trailing whitespace.
            line = line.rstrip()        
            
            # Parse the line trying different matchers.  Quit trying
            # after the first applicable matcher is used.
            for matcher in self.__matchers:
                for match in matcher.finditer(line):
                    self.__match_handler[matcher](self, **match.groupdict())
                    break               # To avoid the else clause.
                else:
                    continue            # The matcher didn't apply.
                break                   # Skip the remaining matchers.
            
        stream.close()            # Explicitly close the input stream.
        
        return self
        
def parse_command_line(command_line_options):
    """Parse the command line according to the possible
    COMMAND_LINE_OPTIONS.
    """
    parser = optparse.OptionParser(usage='%prog [options]...',
                                   version='%%prog %s' % (__version__))
    for option, description in command_line_options:
        parser.add_option(*option, **description)
        
    # Parse the command line.
    return parser.parse_args()
        
def main():
    """Module mainline (for standalone execution).
    """
    command_line_options = [
        (['-O', '--feedback'],
         {'dest': 'feedback',
          'default': None,
          'metavar': 'FILE',
          'help': 'output the new internal InTeX information to FILE ' \
          '(default: %default)'}),
        (['-o', '--index-output'],
         {'dest': 'index_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output the new indexing information to FILE ' \
          '(default: %default)'}),
        (['-a', '--acrodef-output'],
         {'dest': 'acrodef_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output acronym definitions to FILE ' \
          '(default: %default)'}),
        (['-p', '--persondef-output'],
         {'dest': 'persondef_output',
          'default': None,
          'metavar': 'FILE',
          'help': 'output (person) name definitions to FILE ' \
          '(default: %default)'}),
        (['-V', '--verbose'],
         {'dest': 'verbose',
          'default': False,
          'action': 'store_true',
          'help': 'whether or not to output verbose information'}),
        ]

    options, args = parse_command_line(command_line_options)

    logging.root.name = os.path.basename(__file__)

    if options.verbose:
        logging.getLogger().setLevel(logging.INFO)

    indices = [Index.from_file(filename) for filename in args]
    
        
if __name__ == "__main__":
    main()
